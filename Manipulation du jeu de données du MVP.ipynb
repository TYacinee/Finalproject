{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170cd4b6",
   "metadata": {},
   "source": [
    "## Data Manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd99c94",
   "metadata": {},
   "source": [
    "Here is a sample of the final data taken from the website Chasingball. From my dataset I took a sample of 300 plays leading to 600 data concerning players ; the 300 CSV are located in the same file ; with the players data being their statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d636a33b",
   "metadata": {},
   "source": [
    "Let's start manipulating the data, firstly we need to add a column result to specify the winner or the loser in each CSV that we have. For that we use the column goals and the player with the higher number is the winner and the other is the loser. After that we get the files with our 300 plays with the column result.\n",
    "Then we merged them in one dataset so we have one dataset for the 300 plays with the column result.\n",
    "Finally we clean the final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfd281b",
   "metadata": {},
   "source": [
    "### 1. Librairy import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02ef3cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afadf89",
   "metadata": {},
   "source": [
    "### 2. Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b2144",
   "metadata": {},
   "source": [
    "#### 2.1. Creating the column result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18661f",
   "metadata": {},
   "source": [
    "Here we add the column result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9789d",
   "metadata": {},
   "source": [
    "##### 2.1.1. Going through all the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "432318a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create another file were they will be all of our new CSV with the new column.\n",
    "\n",
    "folder_path = r\"C:\\Users\\Yacine\\Downloads\\Analyse de données L2\\MVP\\BallChasing_CSVs\"\n",
    "output_folder = r\"C:\\Users\\Yacine\\Downloads\\Analyse de données L2\\MVP\\BallChasing_CSVs_Final\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Now we go through each CSV.\n",
    "\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e310a68",
   "metadata": {},
   "source": [
    "##### 2.1.2. Creating the column and saving the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36849c41",
   "metadata": {},
   "source": [
    "We add the column result and we choose who is the winner depending on the player with the higher goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e108b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result column is added: 100%|██████████| 300/300 [00:01<00:00, 154.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'result' added in all the CSV : C:\\Users\\Yacine\\Downloads\\Analyse de données L2\\MVP\\BallChasing_CSVs_Final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# We create the column and we add a progression bar to follow the advancement of the code.\n",
    "\n",
    "for file in tqdm(csv_files, desc=\"Result column is added\"):\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=\";\")\n",
    "        \n",
    "        # Find the person with the higher score.\n",
    "        \n",
    "        max_goals = df[\"goals\"].max()\n",
    "\n",
    "        # Wa add the column.\n",
    "        \n",
    "        df[\"result\"] = df[\"goals\"].apply(lambda x: \"winner\" if x == max_goals else \"loser\")\n",
    "        \n",
    "        # We save each CSV in the final file.\n",
    "\n",
    "        output_path = os.path.join(output_folder, file)\n",
    "        df.to_csv(output_path, sep=\";\", index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {file} : {e}\")\n",
    "\n",
    "print(f\"Column 'result' added in all the CSV : {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a4d30",
   "metadata": {},
   "source": [
    "#### 2.2. Merging all the CSV into one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9158519c",
   "metadata": {},
   "source": [
    "Here we will create our final CSV by merging our 300 CSV into one, so we can get our final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820dbcb2",
   "metadata": {},
   "source": [
    "##### 2.2.1. Going through all the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71de73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we go through each CSV.\n",
    "\n",
    "input_folder = r\"C:\\Users\\Yacine\\Downloads\\Analyse de données L2\\MVP\\BallChasing_CSVs_Final\"\n",
    "output_file = r\"C:\\Users\\Yacine\\Downloads\\Analyse de données L2\\MVP\\Dataset_MVP.csv\"\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc606fd6",
   "metadata": {},
   "source": [
    "##### 2.2.2. Creating the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2a4d199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CSV merging:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CSV merging: 100%|██████████| 300/300 [00:01<00:00, 295.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is completed : C:\\Users\\Yacine\\Downloads\\Analyse de données L2\\MVP\\Dataset_MVP.csv\n"
     ]
    }
   ],
   "source": [
    "# We merge all the CSV into one with a progression bar to follow the advancement of the code.\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in tqdm(csv_files, desc=\"CSV merging\"):\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=\";\")\n",
    "        df[\"source_file\"] = file  # We keep the original file\n",
    "        dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"problem with {file} : {e}\")  # To check if there is a problem\n",
    "\n",
    "# Now we create the final dataset.\n",
    "\n",
    "if dataframes:\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    merged_df.to_csv(output_file, sep=\";\", index=False)\n",
    "    print(f\"The dataset is completed : {output_file}\")\n",
    "else:\n",
    "    print(\"The merging didn't work\") # To check if there is a problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02238f4",
   "metadata": {},
   "source": [
    "#### 2.3. Cleaning the final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de93ed23",
   "metadata": {},
   "source": [
    "We clean the final dataset by deleting the columns that we don't need as they are specific to plays in teams but we focus here on solo plays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bb2fbf",
   "metadata": {},
   "source": [
    "##### 2.3.1. Going through the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "070208ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = r\"C:\\Users\\Yacine\\Downloads\\Analyse de données L2\\MVP\\Dataset_MVP.csv\"\n",
    "output_file = r\"C:\\Users\\Yacine\\Downloads\\Analyse de données L2\\MVP\\Final_Dataset_MVP.csv\"\n",
    "df = pd.read_csv(input_file, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46e23f",
   "metadata": {},
   "source": [
    "##### 2.3.2. Dropping the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81ccac",
   "metadata": {},
   "source": [
    "The column that we target are \"team name\", \"assists\" and \"avg distance to team mates\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87529b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns deleted: ['team name', 'assists', 'avg distance to team mates']\n"
     ]
    }
   ],
   "source": [
    "# Deleting the columns that we don't need.\n",
    "\n",
    "cols_to_drop = [\"team name\", \"assists\", \"avg distance to team mates\"]\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "cols_to_drop_normalized = [c.strip().lower() for c in cols_to_drop]\n",
    "cols_to_drop_existing = [c for c in cols_to_drop_normalized if c in df.columns]\n",
    "df = df.drop(columns=cols_to_drop_existing)\n",
    "print(f\"Columns deleted: {cols_to_drop_existing}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f256f",
   "metadata": {},
   "source": [
    "##### 2.3.3. Saving the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03b37846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset created: C:\\Users\\Yacine\\Downloads\\Analyse de données L2\\MVP\\Final_Dataset_MVP.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(output_file, sep=\";\", index=False)\n",
    "print(f\"Final dataset created: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6260870",
   "metadata": {},
   "source": [
    "Now we have the final dataset for the MVP. We will use this sample to see if my project is possible with the prediction models for the MVP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
